"use strict";
/**
 * @license
 * Copyright 2022 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
Object.defineProperty(exports, "__esModule", { value: true });
var tf = require("@tensorflow/tfjs-core");
// tslint:disable-next-line: no-imports-from-dist
var jasmine_util_1 = require("@tensorflow/tfjs-core/dist/jasmine_util");
// tslint:disable-next-line: no-imports-from-dist
var test_util_1 = require("@tensorflow/tfjs-core/dist/test_util");
var depthEstimation = require("../index");
var mask_util_1 = require("../shared/calculators/mask_util");
var test_util_2 = require("../shared/test_util");
// Measured in image channels (values between 0 and 255).
var EPSILON_IMAGE = 2;
function step(edge, x) {
    return x < edge ? 0 : 1;
}
function mix(x, y, a) {
    return x.map(function (value, i) { return value * (1 - a) + y[i] * a; });
}
function saturate(x) {
    return Math.max(Math.min(x, 1), 0);
}
function turboPlus(x) {
    return tf.tidy(function () {
        var d = 1. / 32.;
        var COLORS = [
            [0.4796, 0.0158, 0.0106],
            [0.6754, 0.0898, 0.0045],
            [0.8240, 0.1918, 0.0197],
            [0.9262, 0.3247, 0.0584],
            [0.9859, 0.5048, 0.1337],
            [0.9916, 0.6841, 0.2071],
            [0.9267, 0.8203, 0.2257],
            [0.7952, 0.9303, 0.2039],
            [0.6332, 0.9919, 0.2394],
            [0.4123, 0.9927, 0.3983],
            [0.1849, 0.9448, 0.6071],
            [0.0929, 0.8588, 0.7724],
            [0.1653, 0.7262, 0.9316],
            [0.2625, 0.5697, 0.9977],
            [0.337, 0.443, 0.925],
            [0.365, 0.306, 0.859],
            [0.4310, 0.1800, 0.827],
            [0.576, 0.118, 0.859],
            [0.737, 0.200, 0.886],
            [0.8947, 0.2510, 0.9137],
            [1.0000, 0.3804, 0.8431],
            [1.0000, 0.4902, 0.7451],
            [1.0000, 0.5961, 0.6471],
            [1.0000, 0.6902, 0.6039],
            [1.0000, 0.7333, 0.6157],
            [1.0000, 0.7804, 0.6431],
            [1.0000, 0.8275, 0.6824],
            [1.0000, 0.8706, 0.7255],
            [1.0000, 0.9098, 0.7765],
            [1.0000, 0.9451, 0.8235],
            [1.0000, 0.9725, 0.8588],
            [1.0000, 0.9922, 0.8863],
            [1., 1., 1.]
        ];
        var col = [0, 0, 0];
        var _loop_1 = function (i) {
            var scale_1 = step(d * i, x) - step(d * (i + 1.), x);
            var RHS_1 = mix(COLORS[i], COLORS[i + 1], saturate((x - d * i) / d))
                .map(function (value) { return scale_1 * value; });
            col = col.map(function (value, i) { return value + RHS_1[i]; });
        };
        for (var i = 0.; i < 31.; i++) {
            _loop_1(i);
        }
        // Adds the last white colors after 99%.
        var scale = step(.99, x);
        var RHS = mix(COLORS[31], COLORS[32], saturate((x - .99) / .01))
            .map(function (value) { return scale * value; });
        col = col.map(function (value, i) { return value + RHS[i]; });
        return col.map(function (value) { return value * 255; });
    });
}
(0, jasmine_util_1.describeWithFlags)('ARPortraitDepth', jasmine_util_1.ALL_ENVS, function () {
    var timeout;
    beforeAll(function () {
        timeout = jasmine.DEFAULT_TIMEOUT_INTERVAL;
        jasmine.DEFAULT_TIMEOUT_INTERVAL = 120000; // 2mins
    });
    afterAll(function () {
        jasmine.DEFAULT_TIMEOUT_INTERVAL = timeout;
    });
    it('estimateDepth does not leak memory.', function () { return __awaiter(void 0, void 0, void 0, function () {
        var startTensors, estimator, input, beforeTensors, depthMap;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    startTensors = tf.memory().numTensors;
                    return [4 /*yield*/, depthEstimation.createEstimator(depthEstimation.SupportedModels.ARPortraitDepth)];
                case 1:
                    estimator = _a.sent();
                    input = tf.zeros([128, 128, 3]);
                    beforeTensors = tf.memory().numTensors;
                    return [4 /*yield*/, estimator.estimateDepth(input, { minDepth: 0, maxDepth: 1 })];
                case 2:
                    depthMap = _a.sent();
                    return [4 /*yield*/, depthMap.toTensor()];
                case 3:
                    (_a.sent()).dispose();
                    expect(tf.memory().numTensors).toEqual(beforeTensors);
                    estimator.dispose();
                    input.dispose();
                    expect(tf.memory().numTensors).toEqual(startTensors);
                    return [2 /*return*/];
            }
        });
    }); });
    it('throws error when minDepth is not set.', function (done) { return __awaiter(void 0, void 0, void 0, function () {
        var estimator, input, e_1;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    _a.trys.push([0, 3, , 4]);
                    return [4 /*yield*/, depthEstimation.createEstimator(depthEstimation.SupportedModels.ARPortraitDepth)];
                case 1:
                    estimator = _a.sent();
                    input = tf.zeros([128, 128, 3]);
                    return [4 /*yield*/, estimator.estimateDepth(input)];
                case 2:
                    _a.sent();
                    done.fail('Loading without minDepth succeeded unexpectedly.');
                    return [3 /*break*/, 4];
                case 3:
                    e_1 = _a.sent();
                    expect(e_1.message).toEqual('An estimation config with ' +
                        'minDepth and maxDepth set must be provided.');
                    done();
                    return [3 /*break*/, 4];
                case 4: return [2 /*return*/];
            }
        });
    }); });
    it('throws error when minDepth is greater than maxDepth.', function (done) { return __awaiter(void 0, void 0, void 0, function () {
        var estimator, input, e_2;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    _a.trys.push([0, 3, , 4]);
                    return [4 /*yield*/, depthEstimation.createEstimator(depthEstimation.SupportedModels.ARPortraitDepth)];
                case 1:
                    estimator = _a.sent();
                    input = tf.zeros([128, 128, 3]);
                    return [4 /*yield*/, estimator.estimateDepth(input, { minDepth: 1, maxDepth: 0.99 })];
                case 2:
                    _a.sent();
                    done.fail('Loading with minDepth greater than maxDepth ' +
                        'succeeded unexpectedly.');
                    return [3 /*break*/, 4];
                case 3:
                    e_2 = _a.sent();
                    expect(e_2.message).toEqual('minDepth must be <= maxDepth.');
                    done();
                    return [3 /*break*/, 4];
                case 4: return [2 /*return*/];
            }
        });
    }); });
});
(0, jasmine_util_1.describeWithFlags)('ARPortraitDepth static image ', jasmine_util_1.BROWSER_ENVS, function () {
    var estimator;
    var image;
    var timeout;
    beforeAll(function () { return __awaiter(void 0, void 0, void 0, function () {
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    timeout = jasmine.DEFAULT_TIMEOUT_INTERVAL;
                    jasmine.DEFAULT_TIMEOUT_INTERVAL = 120000; // 2mins
                    return [4 /*yield*/, (0, test_util_2.loadImage)('portrait.jpg', 192, 256)];
                case 1:
                    image = _a.sent();
                    return [2 /*return*/];
            }
        });
    }); });
    afterAll(function () {
        jasmine.DEFAULT_TIMEOUT_INTERVAL = timeout;
    });
    function testBackend(backendName) {
        return __awaiter(this, void 0, void 0, function () {
            var expectedDepthImage, expectedDepthValuesRGBA, expectedDepthValuesRGB, startTensors, beforeTensors, result, actualDepthValues, coloredDepthValues;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, (0, test_util_2.loadImage)('depth.png', 192, 256)];
                    case 1:
                        expectedDepthImage = _a.sent();
                        return [4 /*yield*/, (0, mask_util_1.toImageDataLossy)(expectedDepthImage)];
                    case 2:
                        expectedDepthValuesRGBA = _a.sent();
                        expectedDepthValuesRGB = expectedDepthValuesRGBA.data.filter(function (_, i) { return i % 4 !== 3; });
                        tf.setBackend(backendName);
                        startTensors = tf.memory().numTensors;
                        return [4 /*yield*/, depthEstimation.createEstimator(depthEstimation.SupportedModels.ARPortraitDepth)];
                    case 3:
                        // Get actual depth values.
                        // Note: this makes a network request for model assets.
                        estimator = _a.sent();
                        beforeTensors = tf.memory().numTensors;
                        return [4 /*yield*/, estimator.estimateDepth(image, { minDepth: 0.2, maxDepth: 0.9 })];
                    case 4:
                        result = _a.sent();
                        return [4 /*yield*/, result.toTensor()];
                    case 5:
                        actualDepthValues = _a.sent();
                        coloredDepthValues = actualDepthValues.arraySync().flat().map(function (value) { return turboPlus(value); });
                        (0, test_util_1.expectArraysClose)(coloredDepthValues, expectedDepthValuesRGB, EPSILON_IMAGE);
                        actualDepthValues.dispose();
                        expect(tf.memory().numTensors).toEqual(beforeTensors);
                        estimator.dispose();
                        expect(tf.memory().numTensors).toEqual(startTensors);
                        return [2 /*return*/];
                }
            });
        });
    }
    it('test CPU.', function () { return __awaiter(void 0, void 0, void 0, function () {
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, testBackend('cpu')];
                case 1:
                    _a.sent();
                    return [2 /*return*/];
            }
        });
    }); });
    it('test WebGL.', function () { return __awaiter(void 0, void 0, void 0, function () {
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, testBackend('webgl')];
                case 1:
                    _a.sent();
                    return [2 /*return*/];
            }
        });
    }); });
});
//# sourceMappingURL=ar_portrait_depth_test.js.map